// Generated by scripts/export-ai-context.mjs. Do not edit by hand.

const data = {
  "generatedAt": "2026-01-23T16:39:12.059Z",
  "cv": {
    "version": 1,
    "updatedAt": "2026-01-22",
    "person": {
      "name": "Michał Gacka",
      "headline": "Software Engineer",
      "location": null,
      "contact": {
        "email": "michalgacka@gmail.com",
        "phone": "+48 572 660 445",
        "links": [
          {
            "label": "Website",
            "href": "https://michalgacka.com/",
            "kind": "website"
          },
          {
            "label": "LinkedIn",
            "href": "https://www.linkedin.com/in/michalgacka/",
            "kind": "linkedin"
          },
          {
            "label": "GitHub",
            "href": "https://github.com/m3h0w",
            "kind": "github"
          }
        ],
        "visibility": {
          "phone": true,
          "email": true
        }
      },
      "summary": {
        "paragraphs": [
          "I am a software engineer working with artificial intelligence and full-stack web development. I believe in a world where technology is designed and built first and foremost to do no harm and to make our lives richer and more fulfilling. I take pride in my ability to teach, lead, and make strategic product decisions besides writing clean, maintainable code. In my spare time I enjoy bouldering, playing music, and dancing."
        ]
      },
      "openTo": {
        "roles": [
          "Software Engineer",
          "Machine Learning Engineer",
          "Web Developer",
          "Full Stack Engineer",
          "Computer Vision Engineer"
        ]
      }
    },
    "skills": {
      "highlight": [
        "TypeScript",
        "React",
        "Firebase",
        "Docker",
        "Node.js",
        "Python",
        "Landing Pages",
        "NoSQL",
        "AI-assisted development",
        "Product Management",
        "Leadership",
        "Teaching"
      ],
      "experienced": [
        "NestJS",
        "React Native",
        "Next.js",
        "Supabase",
        "TypeORM",
        "Postgres",
        "DevOps",
        "Machine Learning",
        "Tensorflow",
        "OpenCV",
        "GitHub Actions",
        "Google Cloud",
        "MongoDB",
        "SQL"
      ],
      "favorites": [
        "Python",
        "TypeScript",
        "Tensorflow",
        "Docker",
        "React"
      ]
    },
    "programmingLanguages": {
      "basis": "self-reported",
      "asOf": "2026-01-21",
      "items": [
        {
          "name": "JavaScript",
          "experience": {
            "years": 9
          },
          "category": "professional",
          "enjoyment": 4
        },
        {
          "name": "TypeScript",
          "experience": {
            "years": 8
          },
          "category": "professional",
          "enjoyment": 5
        },
        {
          "name": "Python",
          "experience": {
            "years": 7
          },
          "category": "professional",
          "enjoyment": 5
        }
      ]
    },
    "experience": [
      {
        "company": {
          "name": "SoilSense",
          "website": "https://soilsense.io/",
          "logo": {
            "src": "/images/cv/soilsense.png",
            "alt": "SoilSense",
            "width": 128,
            "height": 128
          }
        },
        "roles": [
          {
            "title": "Lead Software Engineer",
            "employmentType": "Part-time",
            "location": "Copenhagen, Denmark",
            "locationMeta": {
              "mode": "remoteCompanyBased",
              "countryCode": "DK"
            },
            "start": "2023-02",
            "end": null,
            "highlights": [
              "Built a data ingestion pipeline and an online data visualisation dashboard (Progressive Web Application) for a soil moisture sensor system helping farmers save water and grow healthier crops",
              "Used Tensorflow and FastAPI to develop a machine learning algorithm for time series prediction to estimate future values of soil moisture and integrate it into the dashboard",
              "Integrated OpenAI language models into the dashboard to deliver actionable data synthesis and personalized irrigation recommendations via chat"
            ],
            "tech": [
              "TypeScript",
              "React",
              "MobX",
              "Node.js",
              "Firebase",
              "MongoDB",
              "Python",
              "Tensorflow",
              "FastAPI"
            ]
          },
          {
            "title": "Co-Founder & Lead Software Engineer",
            "employmentType": "Full-time",
            "location": "Copenhagen, Denmark",
            "locationMeta": {
              "mode": "onsite",
              "countryCode": "DK"
            },
            "start": "2019-04",
            "end": "2021-11",
            "highlights": [
              "Designed the architecture and built the soil moisture dashboard plus backend services for sensor data ingestion, visualization, and irrigation recommendations"
            ],
            "tech": [
              "React",
              "MobX",
              "TypeScript",
              "Node.js",
              "Express",
              "Firebase",
              "MongoDB",
              "Docker",
              "Google Cloud",
              "Python",
              "FastAPI",
              "Tensorflow"
            ]
          }
        ]
      },
      {
        "company": {
          "name": "Kvalifik",
          "logo": {
            "src": "/images/cv/kvalifik.png",
            "alt": "Kvalifik",
            "width": 128,
            "height": 128
          }
        },
        "roles": [
          {
            "title": "Tech Lead & Senior Full-stack Engineer",
            "employmentType": "Full-time",
            "location": "Copenhagen, Denmark",
            "locationMeta": {
              "mode": "onsite",
              "countryCode": "DK"
            },
            "start": "2022-02",
            "end": "2023-03",
            "highlights": [
              "Introduced consistent software development and teamwork practices in a team of 6 developers, stabilising the delivery process and increasing well-being",
              "Developed role descriptions and product management practices to clarify discovery vs delivery responsibilities and improve customer satisfaction and internal alignment",
              "Built and product-managed a new subscription-based e-commerce platform for a large Danish brewery, increasing MRR by ~300%",
              "Developed a Postgres-based data warehouse synchronised via a NestJS API integration with an external employee management system, cutting monthly salary data analysis time by ~80%"
            ],
            "tech": [
              "TypeScript",
              "React",
              "React Native",
              "Node.js",
              "TypeORM",
              "NestJS",
              "Postgres",
              "Python",
              "Svelte",
              "Docker",
              "Terraform",
              "Google Cloud"
            ]
          }
        ]
      },
      {
        "company": {
          "name": "TIA Technology",
          "logo": {
            "src": "/images/cv/tia.png",
            "alt": "TIA Technology",
            "width": 128,
            "height": 128
          }
        },
        "roles": [
          {
            "title": "ML Software Engineer",
            "employmentType": "Full-time",
            "location": "Copenhagen Area, Denmark",
            "locationMeta": {
              "mode": "onsite",
              "countryCode": "DK"
            },
            "start": "2018-02",
            "end": "2020-01",
            "highlights": [
              "Took a full proof-of-concept product recommendation system from raw data to an API integrated into a front-end solution using Oracle SQL Developer, Python, Scikit-Learn, Flask, and React",
              "Developed a rules-based product recommendation engine using Flask, React, and Docker",
              "Built an integration between an insurance product management layer and the core insurance system API in Java (Spring)"
            ],
            "tech": [
              "Python",
              "Flask",
              "React",
              "Docker",
              "Scikit-Learn",
              "Java",
              "Spring",
              "Oracle SQL"
            ]
          }
        ]
      },
      {
        "company": {
          "name": "GoBundl",
          "logo": {
            "src": "/images/cv/gobundl.png",
            "alt": "GoBundl",
            "width": 128,
            "height": 128
          }
        },
        "roles": [
          {
            "title": "Software Engineer",
            "employmentType": "Full-time",
            "location": "Copenhagen, Denmark",
            "locationMeta": {
              "mode": "onsite",
              "countryCode": "DK"
            },
            "start": "2017-07",
            "end": "2018-01",
            "highlights": [
              "Developed an integration with an email automation provider in C# (ASP.NET)",
              "Built and maintained core product features using HTML/CSS/JavaScript and PostgreSQL",
              "Prototyped product ideas in Python using Flask",
              "In a team of 3, built a futuristic web application for selling insurance to groups of friends — a project that led TIA Technology to acquire GoBundl"
            ],
            "tech": [
              "C#",
              "ASP.NET",
              "JavaScript",
              "HTML",
              "CSS",
              "PostgreSQL",
              "Python",
              "Flask",
              "React"
            ]
          }
        ]
      },
      {
        "company": {
          "name": "Smartin",
          "logo": {
            "src": "/images/cv/smartin.png",
            "alt": "Smartin",
            "width": 128,
            "height": 128
          }
        },
        "roles": [
          {
            "title": "Software Engineer",
            "employmentType": "Contract",
            "location": "Katowice, Poland",
            "locationMeta": {
              "mode": "onsite",
              "countryCode": "PL"
            },
            "start": "2017-01",
            "end": "2017-06",
            "highlights": [
              "Developed a proof of concept parking occupancy detection system in Python and OpenCV",
              "Built a web application in React to display data from air quality sensors"
            ],
            "tech": [
              "Python",
              "OpenCV",
              "JavaScript",
              "React"
            ]
          }
        ]
      },
      {
        "company": {
          "name": "Carnegie Mellon University",
          "logo": {
            "src": "/images/cv/cmu.png",
            "alt": "Carnegie Mellon University",
            "width": 128,
            "height": 128
          }
        },
        "roles": [
          {
            "title": "Computer Vision Research Assistant",
            "employmentType": "Research",
            "location": "Pittsburgh, USA",
            "locationMeta": {
              "mode": "onsite",
              "countryCode": "US"
            },
            "start": "2016-04",
            "end": "2016-10",
            "highlights": [
              "Designed and programmed an algorithm for calculating distance travelled by an endoscopy camera inside a patient’s body using C++ and OpenCV",
              "Improved an existing codebase for providing a map of examination quality during a live colonoscopy exam and delivered a live demo that persuaded the sponsor to extend the project"
            ],
            "tech": [
              "C++",
              "OpenCV"
            ]
          }
        ]
      }
    ],
    "otherActivities": [
      {
        "organization": {
          "name": "Warsaw Institute of Relating",
          "website": "https://www.instytutrelacyjny.pl/",
          "logo": {
            "src": "/images/cv/wir.png",
            "alt": "Warsaw Institute of Relating",
            "width": 128,
            "height": 128
          }
        },
        "title": "Founder",
        "kind": "facilitation",
        "location": "Warsaw, Mazowieckie, Poland (Hybrid)",
        "start": "2025-01",
        "end": null,
        "highlights": [
          "At the Warsaw Institute of Relating we sit together with what is.",
          "Through the practices of Authentic Relating and Relational Contact Improvisation we build our foundation psycho-relational capacities, befriend our emotions, and tame conflict.",
          "We build ourselves into what is needed to hold the metacrisis together."
        ],
        "skills": [
          "Emotional Literacy",
          "Communication",
          "Community Development"
        ],
        "tags": [
          "facilitation",
          "community"
        ]
      }
    ],
    "education": [
      {
        "school": "University of Copenhagen",
        "degree": "MSc",
        "field": "IT & Cognition",
        "location": "Copenhagen, Denmark",
        "locationMeta": {
          "mode": "onsite",
          "countryCode": "DK"
        },
        "logo": {
          "src": "/images/cv/ucph.png",
          "alt": "University of Copenhagen",
          "width": 128,
          "height": 128
        },
        "startYear": 2017,
        "endYear": 2019,
        "achievements": [
          "Average grade: 12/12 (GPA: 4).",
          "Focus: theoretical and practical machine learning, computer vision, cognitive science.",
          "Finished Advanced Topics in Machine Learning and Large Scale Data Analysis with a top grade."
        ],
        "technologies": [
          "Python",
          "Scikit-Learn",
          "Tensorflow",
          "Keras",
          "Hadoop",
          "Spark",
          "OpenCV"
        ],
        "thesis": {
          "title": "Deep learning for segmenting dense tissue and predicting future cancer risk from mammographic X-rays"
        }
      },
      {
        "school": "Silesian University of Technology",
        "degree": "BSc",
        "field": "Automatic Control & Robotics",
        "location": "Gliwice, Poland",
        "locationMeta": {
          "mode": "onsite",
          "countryCode": "PL"
        },
        "logo": {
          "src": "/images/cv/polsl.png",
          "alt": "Silesian University of Technology",
          "width": 128,
          "height": 128
        },
        "startYear": 2012,
        "endYear": 2016,
        "achievements": [
          "Average grade: 4.01/5 (GPA: 3.21).",
          "Focus: foundational maths and physics, low-level programming, computer vision.",
          "Completed a bachelor thesis project in image processing with a grade of 4.5/5."
        ],
        "technologies": [
          "C++",
          "OpenCV",
          "MATLAB"
        ],
        "activities": [
          "IAESTE (marketing, PR, recruitment, mentoring)",
          "CaseWeek",
          "Impro Silesia"
        ]
      }
    ],
    "projects": {
      "recentNonProfit": [
        {
          "name": "Lighthouse CPH – Decentralised booking calendar",
          "location": "Copenhagen, Denmark",
          "start": "2023-02",
          "end": null,
          "highlights": [
            "Implemented a booking calendar for a decentralised, self-organising community.",
            "Used Glide (no-code) and integrated with Stripe using webhooks."
          ],
          "tech": [
            "Glide",
            "Stripe",
            "Webhooks"
          ]
        },
        {
          "name": "uapomoc.pl",
          "location": "Remote, Poland",
          "start": "2022-03",
          "end": "2022-03",
          "highlights": [
            "Helped implement features for a non-profit help directory built in React for Ukrainian refugees in Poland."
          ],
          "tech": [
            "React"
          ]
        }
      ]
    },
    "languages": [
      {
        "name": "English",
        "proficiency": "Fluent"
      },
      {
        "name": "Polish",
        "proficiency": "Fluent"
      }
    ],
    "certifications": [
      {
        "name": "Algorithms on Strings",
        "issuer": "UC San Diego",
        "issued": "2017-02",
        "source": "Coursera"
      },
      {
        "name": "Algorithms on Graphs",
        "issuer": "UC San Diego",
        "issued": "2017-01",
        "source": "Coursera"
      }
    ],
    "volunteering": [
      {
        "organization": "IAESTE Poland",
        "title": "CaseWeek National PR Coordinator",
        "start": "2014-09",
        "end": "2015-09",
        "highlights": [
          "Coordinated PR work for the CaseWeek program."
        ]
      },
      {
        "organization": "IAESTE Poland",
        "title": "Coach, Mentor, Volunteer",
        "start": "2012-10",
        "end": "2016-02",
        "highlights": [
          "Developed a diverse mix of soft skills across PR, communication, recruitment, training, and human relations."
        ]
      }
    ],
    "interests": [
      "Singing",
      "Partner dancing",
      "Guitar",
      "Bouldering",
      "Teaching & coaching"
    ]
  },
  "projects": [
    {
      "slug": "talkling",
      "cover": true,
      "categories": [
        "web app",
        "LLMs",
        "AI",
        "Design / UX",
        "Landing Page"
      ],
      "stack": "Nextjs, LLMs, SQL, Supabase",
      "mainLanguage": "TypeScript",
      "work": {
        "kind": "selfEmployment",
        "entity": "Talkling"
      },
      "country": "Global",
      "i18n": {
        "en": {
          "title": "Talkling",
          "subtitle": "Language-learning SaaS",
          "thumbnail": "/images/thumbnails/talkling1.webp",
          "heroImage": "/images/talkling/hero.webp",
          "description": "Voice-message language practice with live transcription and translations.",
          "links": [
            {
              "label": "Live preview",
              "href": "https://talkling.app/",
              "preview": true
            },
            {
              "label": "Live",
              "href": "https://talkling.app/",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "<a href='https://talkling.app/' target='_blank' rel='noreferrer'>Talkling</a> is a language learning app focused on speaking practice through real conversations. It’s built around voice messages so you can practice at your own pace, without the pressure of real-time calls."
            },
            {
              "type": "image",
              "src": "/images/talkling/talkling2.png",
              "alt": "Talkling conversation demo"
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "Talkling turns each voice message into a learning unit: you can replay audio, read the transcript, and tap messages to see translations. It is designed for partner practice (friends, tutors, language partners) and solo practice via AI characters."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "list",
              "items": [
                "Voice notes with live transcription for every message",
                "Tap-to-translate messages to see instant translations",
                "Optional AI feedback and response suggestions to keep practice flowing"
              ]
            }
          ]
        },
        "pl": {
          "title": "Talkling",
          "subtitle": "Aplikacja SaaS do nauki języków",
          "thumbnail": "/images/thumbnails/talkling1.webp",
          "heroImage": "/images/talkling/hero.webp",
          "description": "Nauka języka przez wiadomości głosowe z transkrypcją i tłumaczeniami.",
          "links": [
            {
              "label": "Podgląd na żywo",
              "href": "https://talkling.app/",
              "preview": true
            },
            {
              "label": "Strona",
              "href": "https://talkling.app/",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "<a href='https://talkling.app/' target='_blank' rel='noreferrer'>Talkling</a> to aplikacja do nauki języków skoncentrowana na ćwiczeniu mówienia w realnych rozmowach. Bazuje na wiadomościach głosowych, dzięki czemu możesz ćwiczyć we własnym tempie, bez presji rozmów na żywo."
            },
            {
              "type": "image",
              "src": "/images/talkling/talkling2.png",
              "alt": "Demo rozmowy w Talkling"
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Każda wiadomość głosowa staje się jednostką nauki: możesz odsłuchać audio, przeczytać transkrypt i kliknąć wiadomości, aby zobaczyć tłumaczenia. Doświadczenie jest zaprojektowane do ćwiczeń w parach oraz do samodzielnej praktyki z postaciami AI."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "list",
              "items": [
                "Notatki głosowe z transkrypcją na żywo dla każdej wiadomości",
                "Kliknięcie wiadomości pokazuje natychmiastowe tłumaczenie",
                "Opcjonalny feedback AI i podpowiedzi odpowiedzi, żeby utrzymać płynność nauki"
              ]
            }
          ]
        }
      }
    },
    {
      "slug": "soilsense",
      "categories": [
        "web app",
        "AI",
        "LLMs",
        "Design / UX"
      ],
      "stack": "React, TypeScript, MongoDB, Firebase, Python, Tensorflow, Docker, GitHub Actions, Google Cloud Platform",
      "mainLanguage": "TypeScript",
      "secondaryLanguage": "Python",
      "work": {
        "kind": "company",
        "entity": "SoilSense"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "SoilSense Irrigation Dashboard",
          "subtitle": "Data-driven web application and AI service",
          "thumbnail": "/images/thumbnails/soilsense.webp",
          "heroImage": "/images/soilsense/charts.png",
          "description": "PWA dashboard that turns farm sensor data into irrigation insights.",
          "links": [
            {
              "label": "Live preview",
              "href": "https://app.soilsense.io/",
              "preview": true
            },
            {
              "label": "Live",
              "href": "https://app.soilsense.io/",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "<a href='https://soilsense.io/' target='_blank' rel='noreferrer'>SoilSense</a> is a sensor system and an online dashboard helping farmers make smarter irrigation decisions."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "The dashboard provides an overview of current sensor statuses and detailed charts with current and historical data transformed and visualized in a simple way. Green \"safe zone\" is derived from a sensor-specific calibration and indicates what values are desirable. We have hundreds of dataloggers deployed to farms all over the world."
            },
            {
              "type": "image",
              "src": "/images/soilsense/map.png",
              "alt": "SoilSense map view"
            },
            {
              "type": "paragraph",
              "html": "Behind the scenes, a notification system can react to newest data and send notifications via multiple channels according to farmer's configuration."
            },
            {
              "type": "paragraph",
              "html": "Artificial Intelligence Service provides data analysis and ML functionality: analytical algorithm that detects field capacity (the 100% available water point) and a timeseries forecasting model that predicts change in water volume 3 days into the future."
            },
            {
              "type": "paragraph",
              "html": "The dashboard also integrates OpenAI's language models to provide actionable data synthesis. Users can interact with a chat interface to ask questions about their sensor data, receive insights, and get personalized irrigation recommendations based on real-time and historical patterns."
            }
          ]
        },
        "pl": {
          "title": "SoilSense – dashboard nawadniania",
          "subtitle": "Aplikacja webowa oparta na danych + warstwa AI",
          "thumbnail": "/images/thumbnails/soilsense.webp",
          "heroImage": "/images/soilsense/charts.png",
          "description": "Dashboard PWA zamieniający dane z sensorów na insighty do nawadniania.",
          "links": [
            {
              "label": "Podgląd na żywo",
              "href": "https://app.soilsense.io/",
              "preview": true
            },
            {
              "label": "Strona",
              "href": "https://app.soilsense.io/",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "<a href='https://soilsense.io/' target='_blank' rel='noreferrer'>SoilSense</a> to system sensorów i internetowy dashboard pomagający rolnikom podejmować lepsze decyzje dotyczące nawadniania."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Dashboard pokazuje statusy sensorów oraz wykresy danych bieżących i historycznych. Zielona \"strefa bezpieczeństwa\" wynika z kalibracji sensora i wskazuje wartości pożądane. System działa produkcyjnie i jest używany przez płacących klientów."
            },
            {
              "type": "image",
              "src": "/images/soilsense/map.png",
              "alt": "Widok mapy SoilSense"
            },
            {
              "type": "paragraph",
              "html": "W tle działa system powiadomień reagujący na najnowsze dane i wysyłający alerty różnymi kanałami zgodnie z konfiguracją rolnika."
            },
            {
              "type": "paragraph",
              "html": "Warstwa AI zapewnia analizę danych i funkcje ML: algorytm wykrywa pojemność polową (100% dostępnej wody), a model szeregów czasowych prognozuje zmiany ilości wody na 3 dni do przodu."
            },
            {
              "type": "paragraph",
              "html": "Dashboard integruje również modele językowe OpenAI, aby zapewnić syntetyzację danych w formie użytecznych wniosków. Użytkownicy mogą korzystać z interfejsu czatu, aby zadawać pytania o swoje dane sensorowe, otrzymywać insighty i personalizowane rekomendacje nawadniania oparte na wzorcach czasu rzeczywistego i historycznych."
            }
          ]
        }
      }
    },
    {
      "slug": "instytut-relacyjny",
      "cover": false,
      "categories": [
        "landing page",
        "Design / UX"
      ],
      "stack": "TypeScript, Next.js, Tailwind",
      "work": {
        "kind": "selfEmployment",
        "entity": "Warsaw Institute of Relating"
      },
      "country": "Poland",
      "i18n": {
        "en": {
          "title": "Warsaw Institute of Relating",
          "subtitle": "Brand website with design & implementation",
          "thumbnail": "/images/thumbnails/instytutrelacyjny__thumbnail.webp",
          "heroImage": "/images/instytutrelacyjny/thumbnail.png",
          "description": "Poetic, SEO-friendly Next.js brand site designed for exploration.",
          "links": [
            {
              "label": "Live preview",
              "href": "https://www.instytutrelacyjny.pl/",
              "preview": true
            },
            {
              "label": "Live",
              "href": "https://www.instytutrelacyjny.pl/",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "<a href='https://www.instytutrelacyjny.pl/' target='_blank' rel='noreferrer'>instytutrelacyjny.pl</a> is a static website I designed and built with Next.js. I’m the founder of the Warsaw Institute of Relating, but this entry focuses on the website as a product: a visual and editorial experience meant to feel beautiful, quiet, and curiosity‑driven — while still being structured, readable, and discoverable (SEO + AI)."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "The goal wasn’t to build something merely simple — it was to build something that feels good to interact with. The site is designed to inspire exploration and a poetic sense of “what’s here?” while keeping the content architecture clear for offerings, schedules, and contact — and keeping the underlying semantics strong for search engines and AI systems."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "orderedList",
              "items": [
                "A modern, responsive layout with generous whitespace and a calm visual rhythm.",
                "A small, consistent design system (typography, spacing, components) that supports a poetic aesthetic.",
                "An information hierarchy that encourages exploration while keeping core actions (offer, schedule, contact) easy to find.",
                "SEO + AI discoverability foundations: semantic markup, descriptive headings, sensible metadata, fast-loading pages.",
                "A deployment setup optimized for a static site workflow and long-term maintainability."
              ]
            },
            {
              "type": "image",
              "src": "/images/instytutrelacyjny/section.png",
              "alt": "Warsaw Institute of Relating website section"
            },
            {
              "type": "paragraph",
              "html": "The site aims to feel calm, polished, and slightly poetic — without sacrificing performance, clarity, or maintainability."
            }
          ]
        },
        "pl": {
          "title": "Warszawski Instytut Relacyjny",
          "subtitle": "Strona marki — projekt i implementacja",
          "thumbnail": "/images/thumbnails/instytutrelacyjny__thumbnail.webp",
          "heroImage": "/images/instytutrelacyjny/thumbnail.png",
          "description": "Poetycka, SEO‑friendly strona w Next.js zachęcająca do eksploracji.",
          "links": [
            {
              "label": "Podgląd na żywo",
              "href": "https://www.instytutrelacyjny.pl/",
              "preview": true
            },
            {
              "label": "Strona",
              "href": "https://www.instytutrelacyjny.pl/",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "<a href='https://www.instytutrelacyjny.pl/' target='_blank' rel='noreferrer'>instytutrelacyjny.pl</a> to statyczna strona, którą zaprojektowałem i zbudowałem w Next.js. Jestem założycielem Warszawskiego Instytutu Relacyjnego, ale tutaj opisuję stronę jako produkt: doświadczenie wizualno‑tekstowe, które ma być piękne, spokojne i rozbudzać ciekawość — przy jednoczesnej dbałości o strukturę treści, SEO i „AI‑discoverability”."
            },
            {
              "type": "image",
              "src": "/images/instytutrelacyjny/thumbnail.png",
              "alt": "Strona Warszawskiego Instytutu Relacyjnego"
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Celem nie było zrobienie “czegoś prostego”. Chodziło o stronę, która ma się dobrze czytać i oglądać: budować nastrój, zachęcać do eksploracji i zostawiać miejsce na ciekawość. Jednocześnie architektura informacji pozostaje klarowna (oferta, terminy, kontakt), a fundamenty semantyczne i metadane wspierają SEO oraz interpretację treści przez systemy AI."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "orderedList",
              "items": [
                "Nowoczesny, responsywny layout z dużą dbałością o oddech (white space) i rytm.",
                "Spójny, mały system UI (typografia, odstępy, komponenty) wspierający spokojną estetykę.",
                "Hierarchia treści, która zachęca do eksploracji, ale nie utrudnia dotarcia do kluczowych informacji.",
                "Podstawy SEO i „AI‑discoverability”: semantyka, opisowe nagłówki, sensowne metadane, szybkie ładowanie.",
                "Wdrożenie i workflow dopasowane do strony statycznej i łatwego utrzymania."
              ]
            },
            {
              "type": "image",
              "src": "/images/instytutrelacyjny/section.png",
              "alt": "Sekcja strony Warszawskiego Instytutu Relacyjnego"
            },
            {
              "type": "paragraph",
              "html": "Strona ma być profesjonalna, spokojna i lekko poetycka — bez rezygnacji z wydajności, czytelności i łatwego utrzymania."
            }
          ]
        }
      }
    },
    {
      "slug": "lighthousecph-events",
      "cover": false,
      "categories": [
        "web app",
        "community project",
        "no code"
      ],
      "stack": "Glide, Stripe Webhooks, Automation",
      "work": {
        "kind": "community",
        "entity": "Lighthouse CPH"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "Lighthouse CPH — Community Calendar",
          "subtitle": "Glide app with Stripe membership logic",
          "thumbnail": "/images/thumbnails/lighthousecph__home.webp",
          "heroImage": "/images/lighthousecph/hero.webp",
          "description": "A community calendar and booking app that verifies paying members via Stripe webhooks.",
          "links": [
            {
              "label": "Live",
              "href": "https://lighthousecph.dk/dl/events",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "A community space calendar app that reacts to Stripe webhooks to determine paid membership status. Members can book spaces for events and see what’s happening in the community."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "The app verifies membership via Stripe webhooks, lets members reserve spaces, and surfaces upcoming events in one calendar experience."
            },
            {
              "type": "heading",
              "text": "Technologies"
            },
            {
              "type": "paragraph",
              "html": "Glide, Stripe webhooks, automation"
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "orderedList",
              "items": [
                "Membership verification based on Stripe webhook events.",
                "Member-friendly booking flow for reserving spaces.",
                "Event calendar view with upcoming activities.",
                "A Glide-based build so non-technical owners can maintain it."
              ]
            },
            {
              "type": "paragraph",
              "html": "Glide was chosen to keep handoff simple for non-technical stakeholders while still supporting webhook-driven logic."
            },
            {
              "type": "heading",
              "text": "Additional Information"
            },
            {
              "type": "paragraph",
              "html": "I made the architectural decisions and set up the membership logic, booking flow, and event inputs in Glide but the current design and content are maintained by the community."
            }
          ]
        },
        "pl": {
          "title": "Lighthouse CPH — Kalendarz społeczności",
          "subtitle": "Aplikacja Glide z logiką członkostwa Stripe",
          "thumbnail": "/images/thumbnails/lighthousecph__home.webp",
          "heroImage": "/images/lighthousecph/hero.webp",
          "description": "Kalendarz i rezerwacje dla społeczności z weryfikacją płatnego członkostwa przez webhooki Stripe.",
          "links": [
            {
              "label": "Strona",
              "href": "https://lighthousecph.dk/dl/events",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Aplikacja kalendarza społecznościowego reagująca na webhooki Stripe, aby określić status płatnego członkostwa. Członkowie mogą rezerwować przestrzeń na wydarzenia i sprawdzać, co się dzieje w społeczności."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Aplikacja weryfikuje członkostwo przez webhooki Stripe, pozwala rezerwować przestrzenie i pokazuje nadchodzące wydarzenia w jednym widoku."
            },
            {
              "type": "heading",
              "text": "Technologie"
            },
            {
              "type": "paragraph",
              "html": "Glide, webhooki Stripe, automatyzacje"
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "orderedList",
              "items": [
                "Weryfikacja członkostwa na podstawie webhooków Stripe.",
                "Przyjazny flow rezerwacji przestrzeni dla członków.",
                "Widok kalendarza z nadchodzącymi wydarzeniami.",
                "Implementacja w Glide, aby ułatwić utrzymanie osobom nietechnicznym."
              ]
            },
            {
              "type": "paragraph",
              "html": "Glide wybrano, aby przekazanie projektu było proste dla osób nietechnicznych, przy zachowaniu logiki opartej o webhooki Stripe."
            },
            {
              "type": "heading",
              "text": "Dodatkowe informacje"
            },
            {
              "type": "paragraph",
              "html": "Zdecydowałem o architekturze i skonfigurowałem logikę członkostwa, flow rezerwacji oraz formularze wydarzeń w Glide, ale obecny design i treści są utrzymywane przez społeczność."
            }
          ]
        }
      }
    },
    {
      "slug": "covid19pink",
      "categories": [
        "web app",
        "community project",
        "Design / UX"
      ],
      "stack": "TypeScript, React, Recharts, Mobx, Vercel",
      "work": {
        "kind": "community"
      },
      "country": "Global",
      "i18n": {
        "en": {
          "title": "COVID19.PINK",
          "subtitle": "Open-source data visualization",
          "thumbnail": "/images/thumbnails/covid19pink.webp",
          "heroImage": "/images/covid19pink.png",
          "description": "Open-source COVID-19 dashboard with an interactive map and trends.",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/covid19-coronavirus-react-visualization"
            },
            {
              "label": "Video",
              "href": "https://vimeo.com/401136287"
            },
            {
              "label": "Live",
              "href": "http://covid19pink.vercel.app/",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "<a href='http://covid19pink.vercel.app/' target='_blank' rel='noreferrer'>COVID19.PINK</a> provides an interactive map, infection trajectory analysis, and country dashboards for engaging people in analysing situation during the pandemic."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "From the start of the pandemic, I appreciated how easily accessible data was but I found the available dashboards hard to read, not easy to interpret and not very engaging."
            },
            {
              "type": "list",
              "items": [
                "a more readable map with a time travel capability",
                "for comparing infection trajectories to easily interpret where in the stages of pandemic your country is"
              ]
            },
            {
              "type": "image",
              "src": "/images/covid19pink/covidmap.gif",
              "alt": "COVID19.PINK map view"
            },
            {
              "type": "heading",
              "text": "Additional Information"
            },
            {
              "type": "paragraph",
              "html": "The application was built as an open-source side project during the early weeks of the COVID-19 pandemic in 2020 to help people better understand the situation through engaging data visualization. At the time I thought the pandemic might last a few weeks or months so the code wasn't optimised for as much data as the application ended up handling."
            }
          ]
        },
        "pl": {
          "title": "COVID19.PINK",
          "subtitle": "Wizualizacja danych open‑source",
          "thumbnail": "/images/thumbnails/covid19pink.webp",
          "heroImage": "/images/covid19pink.png",
          "description": "Open‑source dashboard COVID‑19 z interaktywną mapą i trendami.",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/covid19-coronavirus-react-visualization"
            },
            {
              "label": "Wideo",
              "href": "https://vimeo.com/401136287"
            },
            {
              "label": "Live",
              "href": "http://covid19pink.vercel.app/",
              "preview": false
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "<a href='http://covid19pink.vercel.app/' target='_blank' rel='noreferrer'>COVID19.PINK</a> oferuje interaktywną mapę, analizę trajektorii zakażeń oraz dashboardy krajów, aby ułatwić zrozumienie sytuacji pandemicznej."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Od początku pandemii dane były łatwo dostępne, ale większość dashboardów była trudna w odbiorze i mało angażująca."
            },
            {
              "type": "list",
              "items": [
                "czytelniejsza mapa z funkcją podróży w czasie",
                "porównywanie trajektorii zakażeń, aby łatwiej zrozumieć etap pandemii"
              ]
            },
            {
              "type": "image",
              "src": "/images/covid19pink/covidmap.gif",
              "alt": "Widok mapy COVID19.PINK"
            },
            {
              "type": "heading",
              "text": "Dodatkowe informacje"
            },
            {
              "type": "paragraph",
              "html": "Aplikacja powstała jako open‑source projekt poboczny podczas pierwszych tygodni pandemii COVID-19 w 2020 roku, aby pomóc ludziom lepiej zrozumieć sytuację poprzez angażującą wizualizację danych. W tamtym czasie sądziłem, że pandemia potrwa kilka tygodni lub miesięcy, więc kod nie był zoptymalizowany pod kątem tak dużej ilości danych, jaką aplikacja ostatecznie obsłużyła."
            }
          ]
        }
      }
    },
    {
      "slug": "protein-structure-prediction",
      "categories": [
        "Science",
        "machine learning",
        "AI"
      ],
      "stack": "Python, RNNs, Tensorflow, Jupyter Notebook",
      "work": {
        "kind": "school",
        "entity": "IT University of Copenhagen"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "Protein tertiary structure prediction",
          "subtitle": "Deep learning for protein structure prediction",
          "thumbnail": "/images/thumbnails/protein.webp",
          "heroImage": "/images/protein.png",
          "description": "Predicting 3D protein structure from an amino-acid sequence.",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/protein-dihedral-angles-prediction"
            },
            {
              "label": "Report",
              "href": "https://drive.google.com/file/d/1-SFavU5i6XlHK2sswy60k5TowgButezy/view?usp=sharing"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "The goal of the project was to predict the angles that create the main structure (backbone) of the protein, given information about its aminoacid sequence."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "Predicting proteins’ tertiary structure from their primary structure is one of the most important unsolved problems of biochemistry. Current methods are inaccurate and expensive. Machine Learning offers new toolset that promises cheaper and much more efficient solutions. One of the recent breakthroughs is Mohammed AlQuraishi’s paper on <a href='https://www.biorxiv.org/content/early/2018/02/14/265231.full.pdf' target='_blank' rel='noreferrer'>End-to-end differentiable learning of protein structure</a>, which together with <a href='https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-018-2065-x' target='_blank' rel='noreferrer'>RaptorX-Angle</a>, inspired this project."
            },
            {
              "type": "paragraph",
              "html": "The model was developed for a course but the results go beyond the regular scope of the class."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "We use ProteinNet dataset as introduced by AlQuraishi and write the entire data processing pipeline in Tensorflow. The heart of the model is a Convolutional Neural Network, similar to the one introduced in RaptorX. The model is trained using ADAM optimizer on an MSE and MAE losses between predicted and true dihedral (torsional) angles."
            },
            {
              "type": "paragraph",
              "html": "The LSTM from the image below is thus replaced with a CNN and we don't implement the pink part that would convert the angles into a 3-dimensional, Euclidean space."
            },
            {
              "type": "image",
              "src": "/images/protein/protein_architecture.png",
              "alt": "Protein architecture diagram",
              "caption": "Source: AlQuraishi, End-to-end differentiable learning of protein structure"
            },
            {
              "type": "paragraph",
              "html": "The main challenge in going from a sequence of letters representing amino acids to a 3-dimensional protein structure is 1) an efficient loss calculation and 2) output of the network being angular."
            },
            {
              "type": "orderedList",
              "items": [
                "In the AlQuraishi's paper, protein’s tertiary structure is approximated by 3 torsional angles per amino acid, which then are used to reproduce the 3-dimensional structure to compute loss in that space. That process though is very computationally expensive, thus we’re focusing on a regression task that minimizes the loss between angles directly as also done in the RaptorX paper.",
                "We need to angularize the output of the network to compare it with true angles. As one approach, we predict 3 values directly squeezed into the range of [-pi, pi] by a scaled tanh. Another approach is to predict 6 values split into 3 pairs of 2 where each pair represents a vector in a 2-dimensional space, that can then be converted into an angle using atan2 function."
              ]
            },
            {
              "type": "heading",
              "text": "Results"
            },
            {
              "type": "paragraph",
              "html": "The model developed in this project achieved results on par with results reported in RaptorX while using a smaller feature space. The final report can be found <a href='https://drive.google.com/file/d/1-SFavU5i6XlHK2sswy60k5TowgButezy/view?usp=sharing' target='_blank' rel='noreferrer'>here</a>."
            },
            {
              "type": "heading",
              "text": "My contribution"
            },
            {
              "type": "paragraph",
              "html": "I used Tensorflow to load the data from files saved in the tensor format, prepared a que-based pipeline and a fully differentiable graph that first converts Euclidean coordinates of the protein atoms into its corresponding dihedral angles and then minimizes the loss between angles predicted by the core model and the true angles in the training dataset."
            },
            {
              "type": "paragraph",
              "html": "I experimented with many ways of angularizing the output of the model and developed a clean, modular code available on GitHub."
            }
          ]
        },
        "pl": {
          "title": "Predykcja struktury trzeciorzędowej białek",
          "subtitle": "Deep learning do predykcji struktury białek",
          "thumbnail": "/images/thumbnails/protein.webp",
          "heroImage": "/images/protein.png",
          "description": "Predykcja struktury białka 3D na podstawie sekwencji aminokwasów.",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/protein-dihedral-angles-prediction"
            },
            {
              "label": "Raport",
              "href": "https://drive.google.com/file/d/1-SFavU5i6XlHK2sswy60k5TowgButezy/view?usp=sharing"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Celem projektu było przewidywanie kątów tworzących główną strukturę (szkielet) białka na podstawie sekwencji aminokwasów."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Predykcja struktury trzeciorzędowej białek to jedno z najważniejszych nierozwiązanych zagadnień biochemii. Obecne metody są kosztowne i niedokładne. Uczenie maszynowe daje szansę na tańsze i skuteczniejsze rozwiązania. Przełomem była praca Mohammeda AlQuraishiego <a href='https://www.biorxiv.org/content/early/2018/02/14/265231.full.pdf' target='_blank' rel='noreferrer'>End-to-end differentiable learning of protein structure</a>, która wraz z <a href='https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-018-2065-x' target='_blank' rel='noreferrer'>RaptorX-Angle</a> zainspirowała ten projekt."
            },
            {
              "type": "paragraph",
              "html": "Model powstał na potrzeby kursu, ale wyniki wykraczały poza standardowy zakres zajęć."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Korzystamy z zestawu ProteinNet oraz piszemy cały pipeline przetwarzania danych w Tensorflow. Rdzeniem modelu jest CNN podobny do tego z RaptorX. Model trenujemy optymalizatorem ADAM na stratach MSE i MAE pomiędzy przewidywanymi i prawdziwymi kątami torsyjnymi."
            },
            {
              "type": "paragraph",
              "html": "LSTM z diagramu poniżej zastępujemy CNN i nie implementujemy różowej części, która zamieniałaby kąty na przestrzeń euklidesową 3D."
            },
            {
              "type": "image",
              "src": "/images/protein/protein_architecture.png",
              "alt": "Schemat architektury modelu",
              "caption": "Źródło: AlQuraishi, End-to-end differentiable learning of protein structure"
            },
            {
              "type": "paragraph",
              "html": "Główne wyzwanie to 1) wydajna funkcja straty oraz 2) kątowy charakter wyjścia sieci."
            },
            {
              "type": "orderedList",
              "items": [
                "W pracy AlQuraishiego struktura trzeciorzędowa jest aproksymowana przez 3 kąty torsyjne na aminokwas, a następnie odtwarzana w 3D do obliczenia straty. To kosztowne obliczeniowo, więc minimalizujemy stratę bezpośrednio na kątach, jak w pracy RaptorX.",
                "Wyjście sieci musi być zmapowane na zakres kątów. Jedna metoda to bezpośrednie przewidywanie 3 wartości ograniczonych do [-pi, pi] przez skalowany tanh. Inna to przewidywanie 6 wartości tworzących 3 pary wektorów 2D, które następnie zamieniamy na kąty funkcją atan2."
              ]
            },
            {
              "type": "heading",
              "text": "Wyniki"
            },
            {
              "type": "paragraph",
              "html": "Model osiągnął wyniki porównywalne z RaptorX przy mniejszej przestrzeni cech. Raport końcowy dostępny jest <a href='https://drive.google.com/file/d/1-SFavU5i6XlHK2sswy60k5TowgButezy/view?usp=sharing' target='_blank' rel='noreferrer'>tutaj</a>."
            },
            {
              "type": "heading",
              "text": "Mój wkład"
            },
            {
              "type": "paragraph",
              "html": "Wykorzystałem Tensorflow do wczytywania danych, przygotowałem pipeline kolejkowy i w pełni różniczkowalny graf, który konwertuje współrzędne euklidesowe atomów białka do kątów torsyjnych i minimalizuje stratę między przewidywaniami a prawdziwymi kątami."
            },
            {
              "type": "paragraph",
              "html": "Testowałem różne sposoby „angularizacji” wyjścia modelu i przygotowałem modularny kod dostępny na GitHubie."
            }
          ]
        }
      }
    },
    {
      "slug": "product-recommendation-and-churn",
      "categories": [
        "machine learning",
        "AI"
      ],
      "stack": "Python, Sklearn, Keras, SQL, Docker, Flask",
      "work": {
        "kind": "company",
        "entity": "TIA Technology"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "Product recommendation and churn in insurance",
          "subtitle": "Recommendation system + churn model",
          "thumbnail": "/images/thumbnails/product_recommendation.webp",
          "heroImage": "/images/product_recommendations_and_churn/main.png",
          "description": "Insurance product recommendations and churn prediction models.",
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "The goal is to build a product-grade system for predicting buying behavior of current and prospect customers of insurance companies and a model for predicting the probability of the customer resigning their policy next year."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "The entire insurance industry in Denmark is buzzing with machine learning- and data-driven opportunities yet not many companies attempted to improve their processes using related technologies. As a collaboration between TIA Technology and one of our customers, we set ourselves to build a product recommendation system and a churn model that are going to bring measurable business value and set a precedence for how machine learning can be efficiently used in Nordic insurance market. We use a KNN and Neural Network model for product recommendations and an LSTM and XGBoost for the churn."
            },
            {
              "type": "paragraph",
              "html": "The gif below shows a live integration between a front-end platform and a machine learning API. The predictions of the model change upon an insurance product being added to a customer's profile."
            },
            {
              "type": "image",
              "src": "/images/product_recommendations_and_churn/icp_demo.gif",
              "alt": "Product recommendation demo"
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "We're mostly working with data stored in a data warehouse prepared for the purposes of our BI department, which provides us with expertise regarding the data extraction. We’re using Pandas for data transformations, Sklearn for the product recommendations and Keras for time series modelling. The slides are a part of a presentation for a client we’re working with."
            },
            {
              "type": "subheading",
              "text": "Product recommendation"
            },
            {
              "type": "image",
              "src": "/images/product_recommendations_and_churn/product_recommendation_large.png",
              "alt": "Product recommendation architecture"
            },
            {
              "type": "paragraph",
              "html": "The product recommendation system is built out of 2 parts. KNN model that automatically approximates current customers’ buying behavior by comparing each customer to their closest neighbor, and a Neural Network that does the same for new customers. We use XGBoost to interpret the results in terms of feature importances."
            },
            {
              "type": "image",
              "src": "/images/product_recommendations_and_churn/knn.PNG",
              "alt": "KNN overview"
            },
            {
              "type": "subheading",
              "text": "Churn"
            },
            {
              "type": "image",
              "src": "/images/product_recommendations_and_churn/churn_large.png",
              "alt": "Churn model architecture"
            },
            {
              "type": "paragraph",
              "html": "The churn model works on an insurance policy level, where a year-by-year time series data is used to come up with a probability of the policy not being extended next year. As the baseline we use an XGBoost linear model on the last row before prediction and try to use an RNN to beat its performance."
            },
            {
              "type": "heading",
              "text": "My contribution as an ML Software Engineer"
            },
            {
              "type": "paragraph",
              "html": "I am involved in every part of the pipeline and I'm responsible for the entire process from the data being available in a CSV format, through the conceptualizing, experimentation, model building, communication with the client, to a live API."
            },
            {
              "type": "paragraph",
              "html": "I developed a product recommendation and churn model and created a Flask API for retraining it and exposing its predictions. I integrated it with a front-end application and used docker-compose to make an online version of the product available for demo purposes."
            }
          ]
        },
        "pl": {
          "title": "Rekomendacje produktów i churn w ubezpieczeniach",
          "subtitle": "System rekomendacji + model churn",
          "thumbnail": "/images/thumbnails/product_recommendation.webp",
          "heroImage": "/images/product_recommendations_and_churn/main.png",
          "description": "Rekomendacje produktów ubezpieczeniowych i predykcja churnu.",
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Celem było stworzenie produkcyjnego systemu przewidującego zachowania zakupowe klientów oraz modelu prognozującego prawdopodobieństwo rezygnacji z polisy w kolejnym roku."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Branża ubezpieczeniowa w Danii intensywnie poszukuje zastosowań ML i analityki danych, jednak niewiele firm realnie usprawnia procesy. W ramach współpracy TIA Technology z klientem zbudowaliśmy system rekomendacji oraz model churnu, który miał wnieść mierzalną wartość biznesową. Do rekomendacji użyliśmy KNN i sieci neuronowej, a do churnu – LSTM i XGBoost."
            },
            {
              "type": "paragraph",
              "html": "Poniższy gif pokazuje integrację platformy front‑end z API ML. Predykcje zmieniają się, gdy do profilu klienta dodawany jest produkt."
            },
            {
              "type": "image",
              "src": "/images/product_recommendations_and_churn/icp_demo.gif",
              "alt": "Demo rekomendacji produktów"
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Pracujemy głównie na danych z hurtowni przygotowanej przez dział BI. Transformacje wykonujemy w Pandas, rekomendacje w Sklearn, a modele czasowe w Keras. Slajdy pochodziły z prezentacji dla klienta."
            },
            {
              "type": "subheading",
              "text": "Rekomendacje produktów"
            },
            {
              "type": "image",
              "src": "/images/product_recommendations_and_churn/product_recommendation_large.png",
              "alt": "Architektura rekomendacji produktów"
            },
            {
              "type": "paragraph",
              "html": "System rekomendacji składa się z dwóch części: KNN dopasowuje klientów do najbliższych sąsiadów, a sieć neuronowa obsługuje nowych klientów. Wykorzystujemy XGBoost do interpretacji ważności cech."
            },
            {
              "type": "image",
              "src": "/images/product_recommendations_and_churn/knn.PNG",
              "alt": "Podgląd KNN"
            },
            {
              "type": "subheading",
              "text": "Churn"
            },
            {
              "type": "image",
              "src": "/images/product_recommendations_and_churn/churn_large.png",
              "alt": "Architektura modelu churnu"
            },
            {
              "type": "paragraph",
              "html": "Model churnu działa na poziomie polis. Dane szeregów czasowych pozwalają przewidzieć prawdopodobieństwo nieprzedłużenia polisy. Jako baseline użyliśmy liniowego XGBoost, a następnie próbowaliśmy poprawić wynik przy użyciu RNN."
            },
            {
              "type": "heading",
              "text": "Mój wkład jako ML Software Engineer"
            },
            {
              "type": "paragraph",
              "html": "Byłem zaangażowany w cały pipeline – od danych w CSV, przez eksperymenty i budowę modeli, po komunikację z klientem i wdrożenie API."
            },
            {
              "type": "paragraph",
              "html": "Zbudowałem modele rekomendacji i churnu oraz stworzyłem API Flask do retrainingu i ekspozycji predykcji. Zintegrowałem je z frontendem i użyłem docker‑compose do wersji demo."
            }
          ]
        }
      }
    },
    {
      "slug": "cnns-and-visual-attention",
      "categories": [
        "Science",
        "image processing",
        "AI",
        "machine learning"
      ],
      "stack": "Python, CNN, Tensorflow, Keras, Eye-tracking",
      "mainLanguage": "Python",
      "work": {
        "kind": "school",
        "entity": "University of Copenhagen"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "Visual Attention applied to Object Recognition",
          "subtitle": "Eye-tracking and attention visualization for object recognition",
          "thumbnail": "/images/thumbnails/attention.webp",
          "heroImage": "/images/attention.png",
          "description": "Comparing CNN attention with human eye-tracking.",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/visual-attention-cnn-and-eye-tracking"
            },
            {
              "label": "Report",
              "href": "https://drive.google.com/file/d/1YyhQtbGRLxEe5YRLwyaGAAHkHMd_Escl/view?usp=sharing"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "The aim of the project is to compare how Convolutional Neural Networks and Humans see the world by comparing where computer and human pay attention to during an object recognition task."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "Due to the rise of Visual Attention mechanisms in machine learning it is now possible to model the cognitive process of paying attention in a computer. For a Cognitive Science course project we decided to see if the computer will choose to look at the same thing as a human does to recognize objects of 10 categories and if human eye-tracking data can be used to speed up the process of training the machine learning algorithm."
            },
            {
              "type": "paragraph",
              "html": "The project is part of a Cognitive Science course at the University of Copenhagen."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "We use the <a href='http://calvin.inf.ed.ac.uk/datasets/poet-dataset/' target='_blank' rel='noreferrer'>POET dataset</a> that provides eye-tracking data from multiple annotators that classified over 6 thousand images into 10 categories."
            },
            {
              "type": "image",
              "src": "/images/attention/eye-tracking-fixations.png",
              "alt": "Eye tracking fixations"
            },
            {
              "type": "image",
              "src": "/images/attention/eye-tracking-heatmaps.png",
              "alt": "Eye tracking heatmaps",
              "caption": "Source: http://calvin.inf.ed.ac.uk/datasets/poet-dataset/"
            },
            {
              "type": "paragraph",
              "html": "The project is divided into multiple parts that explore different training environments and relationships between the machine and the human attention:"
            },
            {
              "type": "orderedList",
              "items": [
                "Standard CNN trained with a global pooling layer on top to gain spatially-dependent class activations (<a href='http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf' target='_blank' rel='noreferrer'>reference</a>).",
                "CNN with attention (<a href='https://arxiv.org/pdf/1502.03044.pdf' target='_blank' rel='noreferrer'>reference</a>).",
                "Using eye-tracking data to improve machine learning."
              ]
            },
            {
              "type": "heading",
              "text": "Results"
            },
            {
              "type": "paragraph",
              "html": "The final report can be found <a href='https://drive.google.com/file/d/1YyhQtbGRLxEe5YRLwyaGAAHkHMd_Escl/view?usp=sharing' target='_blank' rel='noreferrer'>here</a>. My work can be found under sections about developing the attention visualization based on gradient theory and comparing CAM, soft attention and human attention."
            },
            {
              "type": "heading",
              "text": "My contribution"
            },
            {
              "type": "paragraph",
              "html": "I came up with the idea for the project and devised the approach. I proposed a novel approach to visualizing human attention from eye-tracking data using gradient theory."
            },
            {
              "type": "paragraph",
              "html": "I developed a soft attention model in Tensorflow and extended an open-source CAM model. I visualized both attention mechanisms and compared them to human attention using PCC."
            }
          ]
        },
        "pl": {
          "title": "Uwaga wzrokowa w rozpoznawaniu obiektów",
          "subtitle": "Eye‑tracking i wizualizacja uwagi w rozpoznawaniu obiektów",
          "thumbnail": "/images/thumbnails/attention.webp",
          "heroImage": "/images/attention.png",
          "description": "Porównanie uwagi CNN z uwagą człowieka (eye‑tracking).",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/visual-attention-cnn-and-eye-tracking"
            },
            {
              "label": "Raport",
              "href": "https://drive.google.com/file/d/1YyhQtbGRLxEe5YRLwyaGAAHkHMd_Escl/view?usp=sharing"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Celem projektu było porównanie tego, jak sieci CNN i ludzie postrzegają świat, analizując obszary uwagi podczas rozpoznawania obiektów."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Rozwój mechanizmów uwagi w ML pozwala modelować proces koncentracji uwagi w komputerze. W projekcie z kognitywistyki sprawdzaliśmy, czy model zwraca uwagę na te same obszary co człowiek, oraz czy dane eye‑tracking pomagają w trenowaniu modelu."
            },
            {
              "type": "paragraph",
              "html": "Projekt realizowany w ramach kursu Cognitive Science na University of Copenhagen."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Wykorzystujemy <a href='http://calvin.inf.ed.ac.uk/datasets/poet-dataset/' target='_blank' rel='noreferrer'>POET dataset</a> z danymi eye‑tracking dla ponad 6 tys. obrazów i 10 klas."
            },
            {
              "type": "image",
              "src": "/images/attention/eye-tracking-fixations.png",
              "alt": "Punkty fiksacji oka"
            },
            {
              "type": "image",
              "src": "/images/attention/eye-tracking-heatmaps.png",
              "alt": "Mapy cieplne uwagi",
              "caption": "Źródło: http://calvin.inf.ed.ac.uk/datasets/poet-dataset/"
            },
            {
              "type": "paragraph",
              "html": "Projekt dzieli się na kilka części badających relacje między uwagą człowieka i modelu:"
            },
            {
              "type": "orderedList",
              "items": [
                "Standardowy CNN z global pooling i mapami aktywacji klas (<a href='http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf' target='_blank' rel='noreferrer'>reference</a>).",
                "CNN z mechanizmem uwagi (<a href='https://arxiv.org/pdf/1502.03044.pdf' target='_blank' rel='noreferrer'>reference</a>).",
                "Wykorzystanie danych eye‑tracking do poprawy uczenia."
              ]
            },
            {
              "type": "heading",
              "text": "Wyniki"
            },
            {
              "type": "paragraph",
              "html": "Raport końcowy dostępny jest <a href='https://drive.google.com/file/d/1YyhQtbGRLxEe5YRLwyaGAAHkHMd_Escl/view?usp=sharing' target='_blank' rel='noreferrer'>tutaj</a>."
            },
            {
              "type": "heading",
              "text": "Mój wkład"
            },
            {
              "type": "paragraph",
              "html": "Byłem autorem pomysłu i opracowałem podejście. Zaproponowałem nowe metody wizualizacji uwagi człowieka na podstawie danych eye‑tracking."
            },
            {
              "type": "paragraph",
              "html": "Zbudowałem model soft‑attention w Tensorflow oraz rozszerzyłem otwarty model CAM. Porównałem mechanizmy uwagi z ludzką uwagą używając PCC."
            }
          ]
        }
      }
    },
    {
      "slug": "endoscopy-quality-evaluation",
      "categories": [
        "Science",
        "image processing",
        "AI"
      ],
      "stack": "C++, OpenCV, OpticalFlow",
      "work": {
        "kind": "school",
        "entity": "Carnegie Mellon University"
      },
      "country": "United States",
      "i18n": {
        "en": {
          "title": "Endoscopy Quality Evaluation",
          "subtitle": "Desktop clinical support tool",
          "thumbnail": "/images/thumbnails/colonoscopy.webp",
          "heroImage": "/images/colonoscopy.png",
          "description": "Desktop tool for real-time colonoscopy quality mapping and reports.",
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "The project aimed to improve the ability to evaluate the performance of a gastroenterologist performing a colonoscopy exam. Software was developed to provide a real-time feedback as well as an after-exam report."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "Due to a relatively high technical difficulty of operating the endoscope during a colonoscopy exam (complicated, unintuitive interface) the success of the procedure is largely dependent on the skills of the doctor. Further, almost no quantitative, universal ways of measuring these skills exist, besides examining the post-factum statistic."
            },
            {
              "type": "paragraph",
              "html": "The project aimed to use only the camera feed in order to objectively and quantitatively evaluate doctor’s performance and output it in real-time for the doctor, as well as provide a report that can then be used to asses doctor’s performance and improvement over time and gather data about how the quality of the examination correlates with detected and missed cancers."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "The software used classical computer vision techniques to asses multiple ways of measuring the quality of the examination. Clarity of the image, how well the patient has been prepared and so on. The most challenging part was a map that was going to approximate directly doctor’s technique in operating the endoscope."
            },
            {
              "type": "image",
              "src": "/images/endoscopy/optical_flow.png",
              "alt": "Optical flow frame",
              "caption": "One frame of Optical Flow in backwards motion"
            },
            {
              "type": "paragraph",
              "html": "For that optical flow was used to calculate the distance traveled by the endoscope in patient’s body and a map was outputted real time that approximated the examined parts of the colon."
            },
            {
              "type": "image",
              "src": "/images/endoscopy/surface_map.png",
              "alt": "Surface map",
              "caption": "The real-time map of visited areas of the colon"
            },
            {
              "type": "heading",
              "text": "My contribution as a Research Assistant"
            },
            {
              "type": "paragraph",
              "html": "I combined together previous work conducted by other Research Assistants and used optical flow to calculate the distance traveled by the camera inside patient’s body. I worked closely with a gastroenterologist and performed a live demo with him during an actual exam."
            }
          ]
        },
        "pl": {
          "title": "Ocena jakości kolonoskopii",
          "subtitle": "Desktopowe narzędzie wsparcia klinicznego",
          "thumbnail": "/images/thumbnails/colonoscopy.webp",
          "heroImage": "/images/colonoscopy.png",
          "description": "Desktopowe narzędzie do mapowania jakości kolonoskopii i raportów.",
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Celem projektu było usprawnienie oceny pracy lekarza wykonującego kolonoskopię. Powstało oprogramowanie zapewniające feedback w czasie rzeczywistym oraz raport po badaniu."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Obsługa endoskopu jest technicznie trudna, a sukces badania zależy w dużej mierze od umiejętności lekarza. Brakuje też obiektywnych metod oceny – poza statystykami po fakcie."
            },
            {
              "type": "paragraph",
              "html": "Projekt wykorzystywał wyłącznie obraz z kamery do ilościowej oceny jakości badania i generował raporty, które pomagają w poprawie jakości oraz analizie korelacji z wykrywalnością zmian."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Wykorzystano klasyczne techniki wizji komputerowej do oceny jakości obrazu i przygotowania pacjenta. Najtrudniejsze było stworzenie mapy obrazującej technikę poruszania endoskopem."
            },
            {
              "type": "image",
              "src": "/images/endoscopy/optical_flow.png",
              "alt": "Przepływ optyczny",
              "caption": "Klatka z analizą przepływu optycznego"
            },
            {
              "type": "paragraph",
              "html": "Na podstawie przepływu optycznego obliczaliśmy drogę endoskopu i tworzyliśmy mapę badanych obszarów."
            },
            {
              "type": "image",
              "src": "/images/endoscopy/surface_map.png",
              "alt": "Mapa powierzchni",
              "caption": "Mapa odwiedzonych obszarów jelita"
            },
            {
              "type": "heading",
              "text": "Mój wkład"
            },
            {
              "type": "paragraph",
              "html": "Połączyłem wcześniejsze prace zespołu, wykorzystałem przepływ optyczny do estymacji przebytej odległości i przeprowadziłem demo z gastroenterologiem podczas realnego badania."
            }
          ]
        }
      }
    },
    {
      "slug": "parking-occupancy-detection",
      "categories": [
        "image processing",
        "AI"
      ],
      "stack": "Python, OpenCV, Google Cloud Storage",
      "work": {
        "kind": "company",
        "entity": "Smart in"
      },
      "country": "Poland",
      "i18n": {
        "en": {
          "title": "Parking Occupancy Detection",
          "subtitle": "Real-time parking occupancy detection (computer vision POC)",
          "thumbnail": "/images/thumbnails/parking.webp",
          "heroImage": "/images/parking.jpg",
          "description": "Camera-based parking occupancy detection POC to replace expensive sensors.",
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "The software was supposed to output information about parking occupancy given a camera feed."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "Poland is drastically developing technologies in the area of urban efficiency and smart cities. The city of Katowice has one of the largest surveillance systems in eastern Europe and is developing complementary technologies to improve quality of life for its citizens. The entire region is now striving to become “smarter” and a part of that goal is being able to improve traffic efficiency and drivers’ comfort by real-time monitoring of parking spaces."
            },
            {
              "type": "paragraph",
              "html": "Current technologies involve expensive electromagnetic sensors that are installed under each parking space. Camera-based technology would theoretically provide much cheaper solution to the problem and could make use of existing surveillance systems."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "The software used a simple Python interface to mark parking spaces on the camera feed and extract high frequency information from these areas to decide if given space has been taken or not. This problem is a perfect case for Machine Learning of course but at the time I haven’t had that expertise yet, thus the use of classical Computer Vision."
            },
            {
              "type": "image",
              "src": "/images/parking/animation.gif",
              "alt": "Parking detection animation"
            },
            {
              "type": "paragraph",
              "html": "The software has never been tested or sold, given that I left to study in Copenhagen and the company decided to use the electromagnetic sensors instead of camera-based solutions."
            },
            {
              "type": "heading",
              "text": "My contribution as Software Engineer"
            },
            {
              "type": "paragraph",
              "html": "I developed the software myself."
            }
          ]
        },
        "pl": {
          "title": "Detekcja zajętości parkingów",
          "subtitle": "Detekcja zajętości miejsc parkingowych (POC, wizja komputerowa)",
          "thumbnail": "/images/thumbnails/parking.webp",
          "heroImage": "/images/parking.jpg",
          "description": "Kamerowa detekcja zajętości parkingu (POC) jako alternatywa dla drogich sensorów.",
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Oprogramowanie miało zwracać informację o zajętości miejsc parkingowych na podstawie obrazu z kamer."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Polska intensywnie rozwija technologie smart city. Katowice mają jeden z największych systemów monitoringu w Europie Wschodniej, co otwiera drogę do optymalizacji ruchu i komfortu kierowców poprzez monitorowanie miejsc parkingowych."
            },
            {
              "type": "paragraph",
              "html": "Obecne rozwiązania opierają się na drogich sensorach elektromagnetycznych montowanych pod każdym miejscem. Wariant oparty o kamery mógłby być tańszy i wykorzystywać istniejącą infrastrukturę."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Zastosowano prosty interfejs w Pythonie do oznaczania miejsc i analizy zmian w obrazie. To klasyczny problem ML, ale wówczas korzystałem z klasycznej wizji komputerowej."
            },
            {
              "type": "image",
              "src": "/images/parking/animation.gif",
              "alt": "Animacja detekcji parkingu"
            },
            {
              "type": "paragraph",
              "html": "Projekt nie trafił do produkcji – po moim wyjeździe firma wybrała sensory elektromagnetyczne."
            },
            {
              "type": "heading",
              "text": "Mój wkład"
            },
            {
              "type": "paragraph",
              "html": "Oprogramowanie stworzyłem samodzielnie."
            }
          ]
        }
      }
    },
    {
      "slug": "traivel",
      "categories": [
        "web app",
        "machine learning",
        "AI"
      ],
      "stack": "Python, JavaScript, Flask, Skyscanner API, Twitter API, Microsoft Cognitive Services",
      "mainLanguage": "Python",
      "secondaryLanguage": "JavaScript",
      "work": {
        "kind": "community"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "TRAiVEL – sentiment-based travel recommendations",
          "subtitle": "Hackathon-built travel recommendation app",
          "thumbnail": "/images/thumbnails/traivel.webp",
          "heroImage": "/images/traivel.png",
          "description": "Hackathon travel recommender combining Twitter sentiment and Skyscanner prices.",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/TRAiVEL"
            },
            {
              "label": "Video",
              "href": "https://vimeo.com/263715035"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "TRAiVEL delivers weekend destination flight prices based on Skyscanner API and visualizes sentiment-based happiness information for these destinations."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "The project was built in around 24 hours in a team of 4 for a hackathon. Won a Skyscanner prize. The goal is to provide users with travel recommendations based on their current location and approximated happiness in the considered European countries."
            },
            {
              "type": "paragraph",
              "html": "The happiness is based on Twitter data scrapped for these countries and filtered to only consider native speakers. That is being sent to Microsoft Cognitive Services that provide sentiment analysis in many European languages (thus the choice of countries). In parallel, we request Skyscanner to provide actionable recommendation that can take he user directly to Skyscanner, where the tickets can be bought."
            },
            {
              "type": "image",
              "src": "/images/traivel/traivel.gif",
              "alt": "TRAiVEL demo"
            },
            {
              "type": "paragraph",
              "html": "Everything is visualized in a form of interactive map that could be adapted to many other data sources than just sentiment information."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "The project was divided into 4 areas and developed in parallel by 4 people to later be integrated into one application: A) Twitter API integration, B) Microsoft Cognitive Services integration, C) Skyscanner API integration D) Main backend and frontend of the app."
            },
            {
              "type": "paragraph",
              "html": "For the backend we’ve used Flask to provide us with as much flexibility in that short time frame as possible and for the frontend we’ve used a library providing the map functionality."
            },
            {
              "type": "paragraph",
              "html": "The separate services have not been integrated together during the hackathon – the app operated on real data but it was statically saved for the purpose of the demo."
            },
            {
              "type": "heading",
              "text": "My contribution"
            },
            {
              "type": "paragraph",
              "html": "I was the author of the idea, designed data flow, guided team’s efforts, so that our separate paths meet, and built the main backend and frontend that integrated all the information."
            }
          ]
        },
        "pl": {
          "title": "TRAiVEL – rekomendacje podróży oparte o sentyment",
          "subtitle": "Hackathonowa aplikacja rekomendacji podróży",
          "thumbnail": "/images/thumbnails/traivel.webp",
          "heroImage": "/images/traivel.png",
          "description": "Hackathonowa aplikacja podróży łącząca sentyment z Twittera i ceny Skyscanner.",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/TRAiVEL"
            },
            {
              "label": "Wideo",
              "href": "https://vimeo.com/263715035"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "TRAiVEL prezentuje ceny lotów na weekend i wizualizuje dane o nastrojach w oparciu o sentyment z Twittera."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Projekt powstał w ok. 24 godziny w 4‑osobowym zespole na hackathonie i zdobył nagrodę Skyscanner. Celem było rekomendowanie podróży na podstawie lokalizacji i przybliżonego poziomu szczęścia w krajach Europy."
            },
            {
              "type": "paragraph",
              "html": "Sentyment bazuje na danych z Twittera, filtrowanych do rodzimych użytkowników, a następnie analizowanych przez Microsoft Cognitive Services. Równolegle pobieramy rekomendacje lotów ze Skyscanner."
            },
            {
              "type": "image",
              "src": "/images/traivel/traivel.gif",
              "alt": "Demo TRAiVEL"
            },
            {
              "type": "paragraph",
              "html": "Wszystko jest wizualizowane na interaktywnej mapie, którą można dostosować do innych źródeł danych."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Projekt podzielono na 4 obszary: A) integracja Twitter API, B) integracja Microsoft Cognitive Services, C) integracja Skyscanner API, D) główny backend i frontend aplikacji."
            },
            {
              "type": "paragraph",
              "html": "Backend napisaliśmy w Flask ze względu na szybkość prototypowania, a frontend oparto o bibliotekę mapową."
            },
            {
              "type": "paragraph",
              "html": "Poszczególne usługi nie zostały w pełni zintegrowane w czasie hackathonu – aplikacja działała na prawdziwych danych, ale zapisanych statycznie na potrzeby demo."
            },
            {
              "type": "heading",
              "text": "Mój wkład"
            },
            {
              "type": "paragraph",
              "html": "Byłem autorem pomysłu, zaprojektowałem przepływ danych, koordynowałem prace zespołu i zbudowałem główny backend oraz frontend integrujący całość."
            }
          ]
        }
      }
    },
    {
      "slug": "t-sne-in-emotion-recognition",
      "categories": [
        "Science",
        "machine learning",
        "AI"
      ],
      "stack": "Python, Keras, Parametric t-SNE",
      "work": {
        "kind": "school",
        "entity": "University of Copenhagen"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "Parametric t-SNE for temporal, multimodal emotion recognition",
          "subtitle": "Emotion recognition visualization with parametric t-SNE",
          "thumbnail": "/images/thumbnails/emotion_recognition.webp",
          "heroImage": "/images/emotion_recognition.png",
          "description": "Parametric t‑SNE “emotion space” for comparing temporal emotion recognition models.",
          "links": [
            {
              "label": "Report",
              "href": "https://drive.google.com/file/d/1j5ZXntRgbDE_mr_5zZtdQdE6zzUx7Mts/view?usp=sharing"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "The research aimed at improving understanding of multimodal emotion recognition models by introducing a framework for visualizing non-temporal and temporal outputs of models predicting multiple related values for each data entry."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "Various emotion recognition models are being introduced with the rise of powerful Machine Learning, computational power, and data sources. Most of them rely on Paul Ekman’s concept of 6 basic emotions, thus predict 6 values in parallel to describe single emotional state."
            },
            {
              "type": "paragraph",
              "html": "This, together with data being merged from different modalities, makes interpreting the results a challenge and opens up opportunities for introducing better visualization techniques that could enable deeper insights, better understanding of the inner workings of machine learning, and ultimately better models."
            },
            {
              "type": "paragraph",
              "html": "Our work introduces a concept called emotion space, and overlays temporal information over that space, allowing for comparison between models and modality-dependent data sources. We present our results for training KNN and LSTM models on the <a href='https://github.com/A2Zadeh/CMU-MultimodalSDK' target='_blank' rel='noreferrer'>CMU MOSEI dataset</a> and a dataset exploring emotion in music."
            },
            {
              "type": "paragraph",
              "html": "The project was developed for a Cognitive Science course."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "The emotion space is created using Parametric t-SNE by embedding the 6-dimensional emotional state into a 2-dimensional space. It represents relationships between the emotions as understand through the prism of training data, grouping similar emotions together and e.g. placing sadness and happiness on one axis where high sadness and high happiness never coincide."
            },
            {
              "type": "image",
              "src": "/images/t-SNE/emotion_space.PNG",
              "alt": "Emotion space",
              "caption": "Emotion Space"
            },
            {
              "type": "paragraph",
              "html": "The crucial point is the use of Parametric t-SNE instead of classical t-SNE. Given that we’ve trained a network that maps training data successfully from 6-, to 2-dimensional space, we can then map any unseen data point into that space again later, visualizing for example predictions of a model trying to learn multimodal emotion recognition task."
            },
            {
              "type": "image",
              "src": "/images/t-SNE/visualization_example.png",
              "alt": "Visualization example",
              "caption": "LSTM minimizing MSE by distinguishing only between happy and not-happy"
            },
            {
              "type": "paragraph",
              "html": "An example could be an LSTM model that produced better MAE than KNN, yet after visualizing the results we could see that it only learned to differentiate between happy and sad. For more information, the full report is available <a href='https://drive.google.com/file/d/1j5ZXntRgbDE_mr_5zZtdQdE6zzUx7Mts/view?usp=sharing' target='_blank' rel='noreferrer'>here</a>."
            },
            {
              "type": "heading",
              "text": "My contribution"
            },
            {
              "type": "paragraph",
              "html": "I authored the idea, worked with parametric t-SNE to create the emotion space, and trained the LSTM model on multiple modalities."
            }
          ]
        },
        "pl": {
          "title": "Parametryczne t-SNE dla czasowej, multimodalnej analizy emocji",
          "subtitle": "Wizualizacja rozpoznawania emocji z parametrycznym t‑SNE",
          "thumbnail": "/images/thumbnails/emotion_recognition.webp",
          "heroImage": "/images/emotion_recognition.png",
          "description": "Parametryczne t‑SNE i „przestrzeń emocji” do porównań modeli temporalnych.",
          "links": [
            {
              "label": "Raport",
              "href": "https://drive.google.com/file/d/1j5ZXntRgbDE_mr_5zZtdQdE6zzUx7Mts/view?usp=sharing"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Celem badań było lepsze zrozumienie modeli rozpoznawania emocji poprzez wizualizację wyników nietemporalnych i temporalnych."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "Wraz z rozwojem ML i dostępnością danych pojawia się wiele modeli rozpoznawania emocji. Większość z nich opiera się na 6 podstawowych emocjach Paula Ekmana i przewiduje 6 wartości jednocześnie."
            },
            {
              "type": "paragraph",
              "html": "Łączenie wielu modalności utrudnia interpretację wyników i otwiera możliwość lepszych technik wizualizacji, które pomagają w zrozumieniu działania modeli."
            },
            {
              "type": "paragraph",
              "html": "Wprowadzamy pojęcie przestrzeni emocji i nakładamy na nią informację temporalną, co pozwala porównywać modele i źródła danych. Wyniki prezentujemy m.in. dla modeli KNN i LSTM trenowanych na <a href='https://github.com/A2Zadeh/CMU-MultimodalSDK' target='_blank' rel='noreferrer'>CMU MOSEI</a>."
            },
            {
              "type": "paragraph",
              "html": "Projekt powstał na kursie Cognitive Science."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Przestrzeń emocji tworzymy przez osadzenie 6‑wymiarowego stanu emocji do 2D za pomocą parametrycznego t‑SNE. Odzwierciedla to relacje między emocjami w danych treningowych."
            },
            {
              "type": "image",
              "src": "/images/t-SNE/emotion_space.PNG",
              "alt": "Przestrzeń emocji",
              "caption": "Przestrzeń emocji"
            },
            {
              "type": "paragraph",
              "html": "Kluczowe jest użycie parametrycznego t‑SNE – wytrenowana sieć pozwala mapować nowe próbki do tej samej przestrzeni, co umożliwia wizualizację predykcji modeli."
            },
            {
              "type": "image",
              "src": "/images/t-SNE/visualization_example.png",
              "alt": "Przykład wizualizacji",
              "caption": "LSTM minimalizuje MSE, rozróżniając głównie happy/not‑happy"
            },
            {
              "type": "paragraph",
              "html": "Przykładowo model LSTM osiąga lepsze MAE od KNN, ale wizualizacja pokazuje, że uczy się głównie rozróżniać happy/sad. Raport dostępny jest <a href='https://drive.google.com/file/d/1j5ZXntRgbDE_mr_5zZtdQdE6zzUx7Mts/view?usp=sharing' target='_blank' rel='noreferrer'>tutaj</a>."
            },
            {
              "type": "heading",
              "text": "Mój wkład"
            },
            {
              "type": "paragraph",
              "html": "Byłem autorem pomysłu, pracowałem z parametrycznym t‑SNE i trenowałem model LSTM na wielu modalnościach."
            }
          ]
        }
      }
    },
    {
      "slug": "insurance-rules-admin-panel",
      "categories": [
        "web app"
      ],
      "stack": "Flask, React, SQLite, Docker",
      "mainLanguage": "JavaScript",
      "secondaryLanguage": "Python",
      "work": {
        "kind": "company",
        "entity": "GoBundl / TIA Technology"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "Insurance Recommendation Admin Panel",
          "subtitle": "Rules-driven recommendations admin panel",
          "thumbnail": "/images/thumbnails/rules_module__overview.webp",
          "heroImage": "/images/rules_module/Start.png",
          "description": "Admin panel for configuring rules-based insurance recommendations.",
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "The web app was build as a POC integrated on top of insurance backend to provide the functionality of setting up rules for displaying insurance depending on customer’s personal information."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "TIA Technology is an insurance backend provider with a broad range of core functionalities for managing insurance business. It is now entering the space of customer- and agent-facing frontends, thus introducing space for personalized, automated user experiences."
            },
            {
              "type": "paragraph",
              "html": "The app allows an insurance employee to set rules for which insurance products should be visible and recommended to customers depending on their personal data. The app exposes an API based on these settings that a frontend solution can then communicate with."
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "A Flask-based backend was coupled with a ReactJS app and SQLite database. The frontend was designed to offer seamless experience, without interrupting the user’s interaction by subsequent API calls – they were handled in the background."
            },
            {
              "type": "image",
              "src": "/images/rules_module/Desktop HD Copy 24.png",
              "alt": "Rules overview",
              "caption": "The overview of created rules*"
            },
            {
              "type": "image",
              "src": "/images/rules_module/Dropdown.png",
              "alt": "Create persona view",
              "caption": "A \"create persona\" view*"
            },
            {
              "type": "heading",
              "text": "My contribution"
            },
            {
              "type": "paragraph",
              "html": "I developed the entire product according to our designer's vision for the frontend."
            },
            {
              "type": "paragraph",
              "html": "*Some details from the screenshots, like search, estimated premium graph, and frequently used rules haven’t been implemented for the POC."
            }
          ]
        },
        "pl": {
          "title": "Panel administracyjny reguł ubezpieczeniowych",
          "subtitle": "Panel reguł rekomendacji",
          "thumbnail": "/images/thumbnails/rules_module__overview.webp",
          "heroImage": "/images/rules_module/Start.png",
          "description": "Panel do definiowania reguł rekomendacji produktów ubezpieczeniowych.",
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Aplikacja webowa była POC zintegrowanym z backendem ubezpieczeniowym i umożliwiała definiowanie reguł wyświetlania produktów w zależności od danych osobowych klienta."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "TIA Technology to dostawca backendu ubezpieczeniowego, który wchodzi w przestrzeń frontendów dla agentów i klientów. To otworzyło miejsce na spersonalizowane doświadczenia."
            },
            {
              "type": "paragraph",
              "html": "Aplikacja pozwalała pracownikom definiować reguły widoczności produktów i udostępniała API, z którego mógł korzystać frontend."
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Backend w Flask został połączony z aplikacją React i bazą SQLite. Interakcje użytkownika nie były blokowane przez wywołania API – wszystko działo się w tle."
            },
            {
              "type": "image",
              "src": "/images/rules_module/Desktop HD Copy 24.png",
              "alt": "Przegląd reguł",
              "caption": "Przegląd utworzonych reguł*"
            },
            {
              "type": "image",
              "src": "/images/rules_module/Dropdown.png",
              "alt": "Widok tworzenia persony",
              "caption": "Widok tworzenia persony*"
            },
            {
              "type": "heading",
              "text": "Mój wkład"
            },
            {
              "type": "paragraph",
              "html": "Zbudowałem całość produktu zgodnie z wizją designu przygotowaną przez projektanta."
            },
            {
              "type": "paragraph",
              "html": "*Niektóre elementy ze zrzutów (np. wyszukiwanie, wykresy premium) nie zostały zaimplementowane w POC."
            }
          ]
        }
      }
    },
    {
      "slug": "cnn-for-furniture-recognition",
      "categories": [
        "Science",
        "image processing",
        "AI",
        "machine learning"
      ],
      "stack": "Azure, CNNs, Keras, Kaggle",
      "mainLanguage": "Python",
      "work": {
        "kind": "school",
        "entity": "University of Copenhagen"
      },
      "country": "Denmark",
      "i18n": {
        "en": {
          "title": "CNNs & Transfer Learning for furniture recognition",
          "subtitle": "Deep learning image classification and Kaggle competition",
          "thumbnail": "/images/thumbnails/furniture.webp",
          "heroImage": "/images/furniture.png",
          "description": "Transfer learning CNN model for 128-class furniture recognition (Kaggle).",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/imaterialist_kaggle_competition"
            },
            {
              "label": "Report",
              "href": "https://drive.google.com/file/d/1BYiLsxVw_Q7rH3k4cbf1DKgqedVDAB_2/view?usp=sharing"
            },
            {
              "label": "Kaggle",
              "href": "https://www.kaggle.com/competitions/imaterialist-challenge-furniture-2018/leaderboard?tab=public"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Project description"
            },
            {
              "type": "paragraph",
              "html": "The model was built on approx. 200.000 images of furniture to distinguish with over 80% accuracy between 128 classes of furniture and accessories."
            },
            {
              "type": "heading",
              "text": "Overview"
            },
            {
              "type": "paragraph",
              "html": "iMaterialist Challenge (Furniture) at FGVC5 introduced a large dataset of furniture for the purpose of performing classification of 128 classes. We’ve used well known pre-trained CNN architectures and ended up with over 80% accuracy on the 175th place out of 428 teams and a maximum grade in the course."
            },
            {
              "type": "paragraph",
              "html": "The project was part of a Large Scale Data Analysis course."
            },
            {
              "type": "image",
              "src": "/images/furniture/rank.PNG",
              "alt": "Kaggle ranking"
            },
            {
              "type": "heading",
              "text": "Technologies"
            },
            {
              "type": "paragraph",
              "html": "Keras, CNNs, Transfer Learning, Ubuntu in Microsoft Azure Cloud"
            },
            {
              "type": "heading",
              "text": "Technical Details"
            },
            {
              "type": "paragraph",
              "html": "We’ve tried many approaches from which we’ve converged on using a full transfer learning approach that combined bottleneck features from 2 different architectures and used test-time augmentation to improve the results further."
            },
            {
              "type": "paragraph",
              "html": "The final model included ResNet50 and DenseNet models proposing predictions in 2 different modes: with and without test-time augmentation, thus the final prediction was a weighted average of probabilities predicted by 4 different modelling pipelines."
            },
            {
              "type": "paragraph",
              "html": "Through the project we’ve worked with Keras using GPU-accelerated Tensorflow in the backend on an Ubuntu machine that we’ve configured ourselves in the Microsoft Azure cloud. An especially challenging part of the project was managing the data in the cloud and working with it efficiently."
            },
            {
              "type": "heading",
              "text": "My contribution"
            },
            {
              "type": "paragraph",
              "html": "I’ve built our transfer learning approach from grounds up, built a framework for extracting and storing bottleneck features, created a data generator because of memory issues, performed test-time augmentation, and created the ensemble that became our final submission."
            }
          ]
        },
        "pl": {
          "title": "CNN i transfer learning do rozpoznawania mebli",
          "subtitle": "Klasyfikacja obrazów w deep learningu i konkurs Kaggle",
          "thumbnail": "/images/thumbnails/furniture.webp",
          "heroImage": "/images/furniture.png",
          "description": "Transfer learning CNN do rozpoznawania 128 klas mebli (Kaggle).",
          "links": [
            {
              "label": "GitHub",
              "href": "https://github.com/m3h0w/imaterialist_kaggle_competition"
            },
            {
              "label": "Raport",
              "href": "https://drive.google.com/file/d/1BYiLsxVw_Q7rH3k4cbf1DKgqedVDAB_2/view?usp=sharing"
            },
            {
              "label": "Kaggle",
              "href": "https://www.kaggle.com/competitions/imaterialist-challenge-furniture-2018/leaderboard?tab=public"
            }
          ],
          "content": [
            {
              "type": "heading",
              "text": "Opis projektu"
            },
            {
              "type": "paragraph",
              "html": "Model zbudowano na ok. 200 tys. obrazów mebli, osiągając ponad 80% trafności dla 128 klas."
            },
            {
              "type": "heading",
              "text": "Przegląd"
            },
            {
              "type": "paragraph",
              "html": "iMaterialist Challenge (Furniture) na FGVC5 dostarczył duży zbiór danych do klasyfikacji 128 klas. Użyliśmy pre‑trenowanych architektur CNN, uzyskując 175. miejsce na 428 zespołów oraz maksymalną ocenę w kursie."
            },
            {
              "type": "paragraph",
              "html": "Projekt realizowany w ramach kursu Large Scale Data Analysis."
            },
            {
              "type": "image",
              "src": "/images/furniture/rank.PNG",
              "alt": "Ranking Kaggle"
            },
            {
              "type": "heading",
              "text": "Technologie"
            },
            {
              "type": "paragraph",
              "html": "Keras, CNN, transfer learning, Ubuntu w chmurze Microsoft Azure"
            },
            {
              "type": "heading",
              "text": "Szczegóły techniczne"
            },
            {
              "type": "paragraph",
              "html": "Zastosowaliśmy pełny transfer learning, łącząc cechy z dwóch architektur i używając test‑time augmentation."
            },
            {
              "type": "paragraph",
              "html": "Końcowy model łączył ResNet50 i DenseNet w dwóch trybach (z i bez TTA), a predykcja była ważoną średnią wyników czterech pipeline’ów."
            },
            {
              "type": "paragraph",
              "html": "Pracowaliśmy z Keras i GPU‑akcelerowanym Tensorflow na maszynie Ubuntu w Azure. Dużym wyzwaniem było efektywne zarządzanie danymi w chmurze."
            },
            {
              "type": "heading",
              "text": "Mój wkład"
            },
            {
              "type": "paragraph",
              "html": "Zbudowałem podejście transfer learning, framework do ekstrakcji cech, generator danych z uwagi na pamięć, test‑time augmentation oraz ensemble końcowy."
            }
          ]
        }
      }
    }
  ]
};

export default data;
